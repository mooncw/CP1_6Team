# CP1_6Team - keypoint detection을 활용한 k-pop 댄스 가이드

## 프로젝트 기간: 6/24 ~ 7/7
### 팀원 및 역할

- 김지우: 팀장, 모델의 설계 및 학습
- 문찬욱: 데이터 베이스 구축, 웹 어플리케이션 구현
- 박효정: EDA를 통한 비즈니스 인사이트 도출
- 이우림: 데이터 전처리 및 모델의 학습

### 프로젝트 개요
1. 2021 스트릿우먼파이터의 성공을 미루어 보았을 때 대한민국 내 댄스 컨텐츠에 대한 호감도가 높은 것을 확인
2. 댄스 레슨을 제공하는 인력은 양적으로 한계가 있으며, 혼자 안무를 따는 것도 다소 어려움이 있음
3. 웹어플리케이션으로 좀더 K-pop 안무를 따기 좋은 환경이 되면, 댄스 컨텐츠에 대한 호감도가 수요로 전환될 것을 염두해 기획

### 사용데이터 
- Kaggle Spotify Data
  - 개발하게 될 모델의 수요를 EDA를 통해 점검하기 위함 
- AI HUB의 K - POP 안무영상 데이터
  - Keypoint Detection Task를 수행할 모델을 만들기 위한 데이터 
  
  
 ### 전처리 과정
 - K - POP 안무 영상 데이터는 이미지화 되어, 1920 * 1080의 사이즈인데, 학습 속도 개선을 위해 320 * 180 으로 바꿈 (각각 1/6을 곱해 줬다.)
 - 이미지를 더 잘 인식하기 위해 모든 픽셀을 255로 나눠 정규화를 했다.
 
 ### 모델의 학습 과정 
 - 다양한 모델을 적용하고자 했으나, 데이터 양이 방대해 코랩을 사용하지 못한점, 로컬에서 GPU 사용에 제한 사항이 있어 CNN을 응용하기로 함
 
 - 학습과정: 80G에 달하는 데이터를 학습시키는데, 너무 많은 시간이 소요되어 이미지 데이터의 갯수와 epoch을 점진적으로 늘려가며 모델을 학습시킴
  - 이미지 데이터 2000개, epochs = 5 => mae: 66.82 수행시간 35분
  - 이미지 데이터 8000개, epochs = 5 => mae: 13.87 수행시간 5시간
  - 이미지 데이터 16000개, epochs = 15 => mae: 8.63 수행시간 14시간
  - 이미지 데이터 32000개, epochs = 20 => mae: 8.22 수행시간 35시간
 
 
 ### 결과
 ![result](https://user-images.githubusercontent.com/95577538/186096962-d7b5f53e-de0e-4a00-a454-226ee62d3a1b.jpg)
 
 - 슈퍼주니어의 sorry sorry 사비 부분 안무를 하는 이미지에 대한 결과
 - 안무가 기준 왼쪽 팔을 올리지 못하고 있는 것으로 보아 아주 정교하게 keypoint를 탐지 하지 못하고 있는 것으로 보임
 - 2~3 개 부분의 관절이 신체에서 이탈되어 있음

 
 ### 한계 및 보완점
 1. 당장 서비스 할 수 있는 수준은 아님 => 정확도 문제, 탈골 현상
 2. 리소스 부족을 해결하면 모델의 교체도 가능하다
  - GPU로 작업할 수 있게 되면, 전이학습모델, Hour glass, transformer를 추가해 더 좋은 모델로 교체 가능
 3. 지금은 이미지에 KeyPoint Detection을 한 수준이지만, 영상 이어 붙인 결과를 보여주거나, 영상에 실시간으로 탐지 결과를 보여 줄 수 있다면 UX 증가 기대 
 4. 가이드 알고리즘 구현 필요
 
 ### 폴더 및 파일 설명
 - dancesite : 구현된 웹 어플리케이션을 확인할 수 있는 폴더
 - model: 모델 학습에 사용된 이미지 데이터 크기 별 결과와 모델의 구조를 확인할 수 있는 폴더 
 - 기타 ipynb 파일 : EDA를 하기 위해 사용된 파일 모음
